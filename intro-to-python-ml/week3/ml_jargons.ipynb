{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Bias in ML?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bias is the error rate of your model on the training dataset.\n",
    "- Bias is how much your model __under-fits__ the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you compute bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Bias = E[y_p - y_t]$$\n",
    "\n",
    "Expected difference between predicted and observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is a learners' tendency to learn the wrong thing\n",
    "-----    \n",
    "\n",
    "Which the following has higher bias?\n",
    "\n",
    "1. $y = \\theta _0$\n",
    "1. $y = \\theta _0 + \\theta _1x $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is bad\n",
    "------\n",
    "\n",
    "An algorithm that has a good ability to fit the training data has __low__ bias.\n",
    "\n",
    "We want to minimize bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms with high bias \n",
    "-------\n",
    "\n",
    "- Produce simple models\n",
    "- Fail to capture meaningful patterns in the data\n",
    "- Under-fit their training data (also don't over-fit either)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to decrease bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Make the model more complex!  \n",
    "\n",
    "You can add more parameters:\n",
    "$y = \\theta _0 + \\theta _1x $  \n",
    "$y = \\theta _0 + \\theta _1x  + \\theta _2x$  \n",
    "$y = \\theta _0 + \\theta _1x  + \\theta _2x + \\theta _3x$  \n",
    "…\n",
    "\n",
    "Or increase model complexity by picking a different algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Larger set of features\n",
    "- Better features\n",
    "\n",
    "Both will increase your model's ability to fit the training dataset, thus lowering bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variance is the amount by which the model result will change for a small change in the input data.\n",
    "- If for a small change in input data, the model results change a lot than the model is said to have high variance\n",
    "- Variance is an algorithm's flexibility to learn patterns in the observed data.\n",
    "- If Variance is high,  that means our model __over-fits__ the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Complexity will Increase Variance \n",
    "------\n",
    "\n",
    "The more complex the model is, the more data points it will \"capture\". \n",
    "\n",
    "However, complexity will make the model \"move\" more to \"capture\" the data points, and hence its variance will be larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance is how much worse you do on the test dataset compared to the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should you do if you have high variance?\n",
    "------\n",
    "\n",
    "1. Feature Selection\n",
    "1. Regularization\n",
    "1. Dimensionality Reduction\n",
    "1. Bagging methods (e.g., Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Vs Variance\n",
    "\n",
    "<center><img src=\"../images/bias_var2.png\" width=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-variance trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of Machine Learning:\n",
    "\n",
    "1. Low bias (model the  patterns in the observed data) \n",
    "1. Low variance (not sensitive to specificities of the observed data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../images/bias_var.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias-variance trade-off: A balancing act\n",
    "------\n",
    "\n",
    "<center><img src=\"../images/abstract_better.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross-validation is a model validation techniques for assessing how the results of a statistical model will generalize to an independent data set. \n",
    "- The goal of cross-validation is to define a data set to test the model in the training phase (i.e. validation data set) in order to limit problems like overfitting,underfitting and get an insight on how the model will generalize to an independent data set. \n",
    "- It is important the validation and the training set to be drawn from the same distribution otherwise it would make things worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is overfitting & underfitting?\n",
    "- Underfitting refers to not capturing enough patterns in the data. The model performs poorly both in the training and the test set.\n",
    "\n",
    "- Overfitting refers: a)capturing noise and b) capturing patterns which do not generalize well to unseen data. The model performs extremely well to the training set but poorly on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1 for Validation: Train/Test split or Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this strategy, we simply split the data into two sets: train and test set so that the sample between train and test set do not overlap, if they do we simply can’t trust our model.\n",
    "\n",
    "<center><img src=\"../images/cv1.png\" width=\"75%\"/></center>\n",
    "\n",
    "BUT:\n",
    "- What if the split we make isn’t random? What if one subset of our data has only people from a certain state, employees with a certain income level but not other income levels, only women or only people at a certain age? . This will result in overfitting, even though we’re trying to avoid it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be viewed as repeated holdout and we simply average scores after K different holdouts. Every data point gets to be in a validation set exactly once, and gets to be in a training set k-1times. This significantly reduces underfitting as we are using most of the data for fitting, and also significantly reduces overfitting as most of the data is also being used in validation set.\n",
    "\n",
    "<center><img src=\"../images/cv2.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters & Hyperparameters - The difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters are learned during training and learned for a specific model on specific data.\n",
    "\n",
    "Hyperparameters are properties of the algorithm.\n",
    "\n",
    "Hyperparameters are set before the start of a training.\n",
    "\n",
    "-----\n",
    "\n",
    "Model parameters are always learned that is why it is Machine Learning.\n",
    "\n",
    "Hyperparameters can be picked or learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
